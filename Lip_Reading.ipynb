{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>0. Install and Import Dependancies</h1>"
      ],
      "metadata": {
        "id": "5ECgiJqlyD8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Install the following depenedancies to our enviroment"
      ],
      "metadata": {
        "id": "OipjNmdB-4IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python matplotlib imageio gdown tensorflow"
      ],
      "metadata": {
        "id": "dJnpSU2Ry2jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  os is for formating our path names\n",
        "*  cv2 is used for loading our video frames\n",
        "*  numpy will be used for processing data/frames\n",
        "*  matplotlib will be used for showing the image frames as we experiment\n",
        "*  imagio can be used to generate a gif of the processed frames\n",
        "*  gdown is a library for downloading from google drive\n",
        "*  finally tensorflow for building, compiling and training our model\n",
        "  *  note: using the legacy adam optimizer seems to be more stable in training"
      ],
      "metadata": {
        "id": "rV3f_U2z_ARt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "import gdown\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
      ],
      "metadata": {
        "id": "_WgKlGdCzrms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  the following lines limit memory growth on our GPU device\n",
        "  *  note this is meant for 0-1 GPU on our machine"
      ],
      "metadata": {
        "id": "Ol95Ind5APPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "gMr0Qmrk0jR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>1. Build Data Loading Functions</h1>"
      ],
      "metadata": {
        "id": "7DIsb7pByLZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  use the reduced dataset from Nicholas Renotte: https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL\n",
        "  *  full dataset for training can be found here https://spandh.dcs.shef.ac.uk//gridcorpus/\n",
        "* we use gdown to download and extract the data"
      ],
      "metadata": {
        "id": "642rZ6DwBOyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
        "output = 'data.zip'\n",
        "gdown.download(download_url,output,quiet=False)\n",
        "gdown.extractall('data.zip')"
      ],
      "metadata": {
        "id": "hpVdtMPW105Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  define our data loading function\n",
        "  *  capture frames using opencv\n",
        "  *  loop through frames and convert to greyscale, crop and scale them\n",
        "  *  we crop the mouth region of the videos staticaly via index slicing\n",
        "  *  the original LipNet paper uses DLib to detect and extract the mouth region"
      ],
      "metadata": {
        "id": "v5jtPGItCgmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path):\n",
        "  capture = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  for i in range(int(capture.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "    ret, frame = capture.read()\n",
        "    frame = tf.image.rgb_to_grayscale(frame)\n",
        "    frames.append(frame[190:236,80:220,:])\n",
        "  capture.release()\n",
        "  mean = tf.math.reduce_mean(frames)\n",
        "  std = tf.math.reduce_std(tf.cast(frames,tf.float32))\n",
        "  return tf.cast((frames - mean),tf.float32)/std"
      ],
      "metadata": {
        "id": "NXuZEdc34Kpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  our vocabulary is all possible characters we can generate in our sentence"
      ],
      "metadata": {
        "id": "-lE11wa1DjpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
      ],
      "metadata": {
        "id": "FyrOH5EU7Kx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  create functions to convert characters to numbers and vice versa\n",
        "*  the StringLookup layer will automatically make the mappings of characters to numbers for us\n",
        "*  oov is the out of vocabulary token. If we encounter a character or number not in the vocabulary we just return an empty string"
      ],
      "metadata": {
        "id": "ivfIBg5XQQQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(),\n",
        "    oov_token=\"\",\n",
        "    invert=True\n",
        ")\n",
        "print(f\"Our Vocabulary is:  {char_to_num.get_vocabulary()}\")\n",
        "print(f\"(size = {char_to_num.vocabulary_size()})\")"
      ],
      "metadata": {
        "id": "T__5Ls017dBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcd90f8-9239-472f-8000-47e79c426051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Vocabulary is:  ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ']\n",
            "(size = 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  take a path to an alignment file and return the integer tokens representing those alignments\n",
        "  *  these are our labels for what is said in the video\n",
        "*  ignore lines that map to \"sil\" as this is a special case which represents silence in the alignments"
      ],
      "metadata": {
        "id": "J3MkgDDxRaHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignments(path):\n",
        "  with open(path,'r') as f:\n",
        "    lines = f.readlines()\n",
        "  tokens = []\n",
        "  for line in lines:\n",
        "    line = line.split()\n",
        "    if line[2] != 'sil':\n",
        "      tokens = [*tokens, ' ', line[2]]\n",
        "  return char_to_num(tf.reshape(tf.strings.unicode_split(tokens,input_encoding='UTF-8'),(-1)))[1:]"
      ],
      "metadata": {
        "id": "ikisjPZV9Ka1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  load both alignments(labels) and video frames(data)\n",
        "*  given a path extract the file name without the extension\n",
        "  *  this code assumes a windows file path formating replace the '/' with '\\\\' for linux file systems\n",
        "*  search our data folder for the video file path and the alignment file path that corresponds to it\n",
        "*  load the two files using previously defined functions"
      ],
      "metadata": {
        "id": "6MSlS2sgmeIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  path = bytes.decode(path.numpy())\n",
        "  file_name = path.split('/')[-1].split('.')[0]\n",
        "  video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
        "  align_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
        "  frames = load_video(video_path)\n",
        "  aligmnets = load_alignments(align_path)\n",
        "  return frames, aligmnets"
      ],
      "metadata": {
        "id": "tkYkJADk-Cgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  use a example path to test the data loading functions"
      ],
      "metadata": {
        "id": "ALnqM0J5ncjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = './data/s1/bbaf2n.mpg'\n",
        "load_data(tf.convert_to_tensor(test_path))"
      ],
      "metadata": {
        "id": "l2tMfc2d-9Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  TensorFlow Datasets require the data loading function to be wrapped in a TensorFlow py function to use it in the pipeline"
      ],
      "metadata": {
        "id": "3cTou568niBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mappable_load_data(path):\n",
        "  res_fnc = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
        "  return res_fnc"
      ],
      "metadata": {
        "id": "ySTe6ZqVA4Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>2. Create Data Pipeline</h1>"
      ],
      "metadata": {
        "id": "iUNA25TIyPDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  create the data loading pipeline\n",
        "  * we list all of the video files in our data folder\n",
        "  * we then shuffle them\n",
        "  * we use our mappable data loading function to grab all of the frames and alignments\n",
        "  * we pad the data to ensure that each frame array is 75 frames long and each alignment is 40 characters long to ensure compatibility in the training steps\n",
        "  * we also fetch 2 videos/alignments at a time\n",
        "  * finally we load in the data\n",
        "    *  I use the keras split_dataset function to split the data evenly in half between training and test data. This uses much more RAM(5-8GB) and thus I recommend it for systems with at least 12GB RAM\n",
        "    *  Alternatively you can used the commented out take/skip method but I find this more unstable in training as well as taking significantly longer to train( aproximatly 8x slower in my experience)"
      ],
      "metadata": {
        "id": "3-oUKkD1obrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_load_data)\n",
        "data = data.padded_batch(2,padded_shapes=([75,None,None,None],[40]))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "#train_data = data.take(450)\n",
        "#test_data = data.skip(450)\n",
        "train_data, test_data = tf.keras.utils.split_dataset(data, left_size=0.5)"
      ],
      "metadata": {
        "id": "8WyK0wwe2zSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  visualize our frame data\n",
        "  *  use imageio to create a animated gif of one of the videos and output it to the root folder of our project\n",
        "  *  display a frame from frame 0-74 in our processed video useing matplotlib"
      ],
      "metadata": {
        "id": "JgbLcwjOqk2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "dgYG1orb4ToO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageio.mimsave('./lip_animation.gif',sample_data[0][0],fps=10)"
      ],
      "metadata": {
        "id": "-YeUXrCr4wEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_to_display = 15\n",
        "plt.imshow(sample_data[0][0][frame_to_display])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "0Txb3TYM5Ojx",
        "outputId": "422d3373-cc3e-4d26-b4a7-0dfe58b3e04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f31fb9b9630>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  display the aligment(sentence) that corresponds to the video we are visualizing"
      ],
      "metadata": {
        "id": "TvuvOGZ-rpoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([num_to_char(word) for word in sample_data[1][0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cw736OA5vgo",
        "outputId": "06ea6895-4c4b-47c9-eb45-88a5bd32ac35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'lay blue in d three soon'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>3. Design the Deep Neural Network</h1>"
      ],
      "metadata": {
        "id": "Dt-Je49OySdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Defining the Model\n",
        "  * we start with 3 sets of the following layers:\n",
        "    *  3D convulotion with 3x3x3 kernals, first we use input of our 75 video frames and feed forward to our next layer. Also we use 128,256,75 kernals respectivly\n",
        "    *  a ReLU activation layer\n",
        "    *  a final Max Pooling layer that takes the Max values of our input in 2x2x1 squares to condense it\n",
        "  *  we flatten the output of the previous step as a time series to be accepted by our LSTM layers\n",
        "  *  we use LSTM(LongShortTermMemory) layers to provide the models memory (these LSTM layers will be bidrectional)\n",
        "    *  note the original LipNet paper uses GRU layers instead of LSTM layers\n",
        "  * we use a dropout with a 50% chance for some regularization in our model\n",
        "  * finally we use a Dense softmax layer to determine which character in our vocabulary is being predicted in each step\n",
        "  "
      ],
      "metadata": {
        "id": "0I6gXWLZscSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(128,3,input_shape=(75,46,140,1),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256,3,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(75,3,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,kernel_initializer='Orthogonal',return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128,kernel_initializer='Orthogonal',return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1,kernel_initializer='he_normal', activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4mPu8xBhxly",
        "outputId": "f76a5255-41d3-499a-f820-ca84bd57ca73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_3 (Conv3D)           (None, 75, 46, 140, 128)  3584      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 75, 46, 140, 128)  0         \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPooling  (None, 75, 23, 70, 128)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 75, 23, 70, 256)   0         \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPooling  (None, 75, 11, 35, 256)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 75, 11, 35, 75)    0         \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPooling  (None, 75, 5, 17, 75)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 75, 6375)         0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 75, 256)          6660096   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 75, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 75, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 75, 256)           0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 75, 41)            10537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,471,924\n",
            "Trainable params: 8,471,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  test our models predictions before training"
      ],
      "metadata": {
        "id": "eyK343Rgxkl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test prediction')\n",
        "test_prediction = model.predict(sample_data[0])\n",
        "print(tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in test_prediction[1]]))\n",
        "\n",
        "print(f'model input shape: {model.input_shape}')\n",
        "print(f'model output shape: {model.output_shape}')"
      ],
      "metadata": {
        "id": "P14E4dxhkykQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>4. Setup Training Options and Train</h1>"
      ],
      "metadata": {
        "id": "2tBAbfgZyYGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  after 30 epochs lower the learning rate using an exponential function"
      ],
      "metadata": {
        "id": "h31By6q0-oK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch,lr):\n",
        "  if epoch < 30:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr *tf.math.exp(-0.1)"
      ],
      "metadata": {
        "id": "80Km9qvwoOsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  define the CTCLoss method\n",
        "  *  this will lower chance of redudant predicted words\n",
        "  *  this is also better performing for unaligned data if you were to take this into an app that live predicted a video feed\n",
        "  *  video explaining CTC Loss: https://www.youtube.com/watch?v=GxtMbmv169o"
      ],
      "metadata": {
        "id": "-iabBUmN-8D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CTCLoss(y_true,y_pred):\n",
        "  batch_len = tf.cast(tf.shape(y_true)[0],dtype=\"int64\")\n",
        "  input_len = tf.cast(tf.shape(y_pred)[1],dtype=\"int64\")\n",
        "  label_len = tf.cast(tf.shape(y_true)[1],dtype=\"int64\")\n",
        "\n",
        "  input_len = input_len * tf.ones(shape=(batch_len,1), dtype=\"int64\")\n",
        "  label_len = label_len * tf.ones(shape=(batch_len,1), dtype=\"int64\")\n",
        "\n",
        "  loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_len, label_len)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "JzdYWoqUobUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  use callback subclassing to show the original annotation vs the predicted anotation the model would produce at the end of each epoch"
      ],
      "metadata": {
        "id": "8l_Akq3wACSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProduceExample(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, dataset):\n",
        "    self.dataset = dataset.as_numpy_iterator()\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    data = self.dataset.next()\n",
        "    yhat = self.model.predict(data[0])\n",
        "    decoded = tf.keras.backend.ctc_decode(yhat,[75,75], greedy=False)[0][0].numpy()\n",
        "    for x in range(len(yhat)):\n",
        "      print(\"Original:\", tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "      print(\"Prediction:\", tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "      print('~'*100)"
      ],
      "metadata": {
        "id": "idW8d67oq2yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
      ],
      "metadata": {
        "id": "KWth67N_sUFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  we are setting up our callbacks so that the learning rate scheduler is used our example callback is used and that at the end of each epoch we save our model weights to a checkpoint"
      ],
      "metadata": {
        "id": "kW8pjdyRA1Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "example_callback = ProduceExample(test_data)"
      ],
      "metadata": {
        "id": "B_cIjPTjtEs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  you can toggle load_model to either load a checkpoint or train the model"
      ],
      "metadata": {
        "id": "ICUyJ0_uBICP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = False\n",
        "if(load_model):\n",
        "  model.load_weights('./models/checkpoint')\n",
        "else:\n",
        "  model.fit(train_data,validation_data=test_data, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])\n"
      ],
      "metadata": {
        "id": "gfMFujdSubjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>5. Make a Prediction</h1>"
      ],
      "metadata": {
        "id": "XpmDt5QLylv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  you can download the weights for a 100 epoch model I trained from: https://drive.google.com/u/0/uc?id=19aX5ESgsMtrOVchHb_IDK95XrqmX_-2u\n",
        "*  we then can get the predictions from our test data one at a time to verify our model is working"
      ],
      "metadata": {
        "id": "kMum8S9qBrZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_url = 'https://drive.google.com/u/0/uc?id=19aX5ESgsMtrOVchHb_IDK95XrqmX_-2u'\n",
        "output = 'checkpoint.zip'\n",
        "gdown.download(checkpoint_url, output, quiet=False)\n",
        "gdown.extractall('checkpoint.zip','models')\n",
        "model.load_weights('models/checkpoint')"
      ],
      "metadata": {
        "id": "ewCOqr2Q3-Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = test_data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "dC_8U5uTARXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  run this code cell each time to get a new set of two predictions from test data"
      ],
      "metadata": {
        "id": "1wX5meLlCOYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = sample_data.next()\n",
        "prediction =  model.predict(sample[0])\n",
        "decoded = tf.keras.backend.ctc_decode(prediction, input_length=[75,75], greedy=True)[0][0].numpy()\n",
        "print('~'*30,'PREDICTIONS','~'*30)\n",
        "print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded][0])\n",
        "print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded][1])\n",
        "print('~'*30,'REAL TEXT','~'*30)\n",
        "print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]][0])\n",
        "print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMu3Rvj_4VWd",
        "outputId": "a3ace307-ef5c-490b-851f-6d39bc563fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "tf.Tensor(b'bin blue by m seve soon', shape=(), dtype=string)\n",
            "tf.Tensor(b'lay white by f four please', shape=(), dtype=string)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "tf.Tensor(b'bin blue by f seven soon', shape=(), dtype=string)\n",
            "tf.Tensor(b'lay white by f four please', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>6. Test on Video</h1>"
      ],
      "metadata": {
        "id": "QZkoeZVIyqbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  test specific videos by substituting in the /path/to/video and running the following code cell"
      ],
      "metadata": {
        "id": "ifjE58B4CX0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = load_data(tf.convert_to_tensor('/path/to/video'))\n",
        "prediction = model.predict(tf.expand_dims(sample_data[0],axis=0))\n",
        "decoded = tf.keras.backend.ctc_decode(prediction,input_length=[75], greedy=True)[0][0].numpy()\n",
        "print('~'*30,'PREDICTIONS','~'*30)\n",
        "print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded][0])\n",
        "print('~'*30,'REAL TEXT','~'*30)\n",
        "print([tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample_data[1]]][0])"
      ],
      "metadata": {
        "id": "OzNj1Y2i8nGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892df0a1-3c8f-4334-c766-0cd0c5a90eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "tf.Tensor(b'bin green at n five soon', shape=(), dtype=string)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "tf.Tensor(b'bin green at n five soon', shape=(), dtype=string)\n"
          ]
        }
      ]
    }
  ]
}